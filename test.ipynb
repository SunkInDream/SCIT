{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06111fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_impute import *\n",
    "from pygrinder import block_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be2511",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/lorenz/lorenz_dataset_0_timeseries.csv\",header=None)\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35727148",
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = pd.read_csv('./causality_matrices/lorenz_causality_matrix.csv', header=None)\n",
    "cg = cg.values\n",
    "model_params = {\n",
    "        'num_levels': 10,\n",
    "        'kernel_size': 8,\n",
    "        'dilation_c': 2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f8b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = block_missing(data[np.newaxis,...],factor=0.1, block_len=3, block_width=3)\n",
    "data = data[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3939b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputed = impute(data, cg, model_params)\n",
    "data_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd675b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_miracle.py\n",
    "import numpy as np\n",
    "from baseline import miracle_impu\n",
    "\n",
    "# 创建测试数据\n",
    "test_data = np.random.randn(100, 10)\n",
    "test_data[np.random.random((100, 10)) < 0.1] = np.nan\n",
    "\n",
    "print(\"测试数据形状:\", test_data.shape)\n",
    "print(\"缺失值数量:\", np.isnan(test_data).sum())\n",
    "\n",
    "try:\n",
    "    result = miracle_impu(test_data)\n",
    "    print(\"MIRACLE结果形状:\", result.shape if result is not None else \"None\")\n",
    "    print(\"MIRACLE结果类型:\", type(result))\n",
    "    \n",
    "    if result is not None:\n",
    "        print(\"填补后缺失值:\", np.isnan(result).sum())\n",
    "    else:\n",
    "        print(\"❌ MIRACLE返回了None\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ MIRACLE测试失败: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf579a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 读取 CSV 文件\n",
    "zero_matrix = pd.read_csv(\"zero_impu_matrix.csv\").values  # shape: (T, N)\n",
    "\n",
    "# 构造掩码矩阵：0 的位置为 0，其余为 1\n",
    "mask_matrix = np.where(zero_matrix == 0, 0, 1)\n",
    "\n",
    "# 保存新矩阵到 CSV\n",
    "pd.DataFrame(mask_matrix).to_csv(\"zero_impu_mask.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8077a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa10119",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv('./train_result.csv').values\n",
    "gt = pd.read_csv('./gt_matrix.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fbe677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5372529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_matrix = 1 - mask_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af7e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred*mask_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64647142",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt*mask_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d45f1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = F.mse_loss(torch.tensor(pred*mask_matrix), torch.tensor(gt*mask_matrix))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f44c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "tmp_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "tmp_file.close()\n",
    "os.remove(tmp_file.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a02438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 原始目录和目标目录路径\n",
    "src_dir = './data/III'        # 替换为你的源目录路径\n",
    "dst_dir = './data/mimic-iii'   # 替换为你的目标目录路径\n",
    "\n",
    "# 创建目标目录（如果不存在）\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "# 获取源目录中的所有文件名（按名称排序，可改为按修改时间等）\n",
    "all_files = sorted(f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f)))\n",
    "\n",
    "# 选择前100个文件\n",
    "files_to_move = all_files[:100]\n",
    "\n",
    "# 移动文件\n",
    "for fname in files_to_move:\n",
    "    shutil.move(os.path.join(src_dir, fname), os.path.join(dst_dir, fname))\n",
    "\n",
    "print(f\"已成功移动 {len(files_to_move)} 个文件到 {dst_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9813c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 23:29:49 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗\n",
      "╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║\n",
      "   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║\n",
      "   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║\n",
      "   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║\n",
      "   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝\n",
      "ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai \u001b[0m\n",
      "\n",
      "填补前后对比（仅缺失位置）：[[ 93.       137.        64.       ...  60.061043  60.061043   0.      ]\n",
      " [  0.         0.         0.       ...  60.061043  60.061043   7.      ]\n",
      " [  0.         0.         0.       ...  60.061043  60.061043   0.      ]\n",
      " ...\n",
      " [  0.         0.         0.       ...  60.061043  60.061043   0.      ]\n",
      " [  0.         0.         0.       ...  60.061043  60.061043   0.      ]\n",
      " [  0.         0.         0.       ...  60.061043  60.061043   0.      ]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from baseline import *\n",
    "from models_impute import *\n",
    "# 指定目录\n",
    "data_dir = \"./data/III\"  # 替换为你的目录路径\n",
    "\n",
    "# 获取目录下第一个 CSV 文件\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith(\".csv\")]\n",
    "assert csv_files, \"目录中没有找到 CSV 文件\"\n",
    "csv_path = os.path.join(data_dir, csv_files[0])\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv(csv_path)\n",
    "mx = df.values.astype(np.float32)\n",
    "\n",
    "# 记录原始缺失位置\n",
    "nan_pos = np.argwhere(np.isnan(mx))\n",
    "\n",
    "# 填补缺失值\n",
    "imputed_mx = timesnet_impu(mx,)\n",
    "\n",
    "# 打印填补前后的值（仅缺失位置）\n",
    "print(f\"填补前后对比（仅缺失位置）：{imputed_mx}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95acbcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkgutil\n",
    "import sys\n",
    "\n",
    "for _, name, _ in pkgutil.iter_modules():\n",
    "    if 'tsde' in name:\n",
    "        print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "500e6b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 保存至: ./finance_dataset_0_timeseries_dig_missing.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pygrinder import mcar, mar_logistic, mnar_x\n",
    "\n",
    "def dig_missing_values(\n",
    "    file_path: str,\n",
    "    output_dir: str,\n",
    "    obs_rate: float = 0.4,\n",
    "    mar_missing_rate: float = 0.6,\n",
    "    mnar_offset: float = 0.7,\n",
    "    mcar_p: float = 0.1\n",
    "):\n",
    "    # 读取数据\n",
    "    df = pd.read_csv(file_path)\n",
    "    data = df.values.astype(np.float32)\n",
    "    \n",
    "    # 应用缺失机制\n",
    "    X = mar_logistic(data, obs_rate=obs_rate, missing_rate=mar_missing_rate)\n",
    "    X = X[np.newaxis, ...]                  # 添加 batch 维度\n",
    "    X = mnar_x(X, offset=mnar_offset)       # MNAR 缺失\n",
    "    X = mcar(X, p=mcar_p)                   # 再次添加 MCAR 缺失\n",
    "    X = X.squeeze(0)                        # 去除 batch 维度\n",
    "\n",
    "    # 保存结果\n",
    "    filename = os.path.basename(file_path).replace('.csv', '_dig_missing.csv')\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    pd.DataFrame(X).to_csv(output_path, index=False)\n",
    "    print(f\"✅ 保存至: {output_path}\")\n",
    "dig_missing_values(\n",
    "    file_path='./data/finance/finance_dataset_0_timeseries.csv',\n",
    "    output_dir='./',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsdb\n",
    "\n",
    "# list all available datasets in TSDB\n",
    "tsdb.list()\n",
    "# ['physionet_2012',\n",
    "#  'physionet_2019',\n",
    "#  'electricity_load_diagrams',\n",
    "#  'beijing_multisite_air_quality',\n",
    "#  'italy_air_quality',\n",
    "#  'vessel_ais',\n",
    "#  'electricity_transformer_temperature',\n",
    "#  'pems_traffic',\n",
    "#  'solar_alabama',\n",
    "#  'ucr_uea_ACSF1',\n",
    "#  'ucr_uea_Adiac',\n",
    "#  ...\n",
    "\n",
    "tsdb.download_and_extract('beijing_multisite_air_quality', './save_it_here')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Former",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
